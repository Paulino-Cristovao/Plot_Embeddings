### Using basic CNN plot the embeddings
### We often evaluate the embeddings in the validation loop

# Validation
def validate(val_loader_train, model, criterion, epoch):
    losses = AverageMeter()
    top1 = AverageMeter()

    out_target = []
    out_data = []
    out_output = []
    feat_ = []

    # switch to evaluate mode
    model.eval()
    with torch.no_grad():
        for batch_idx, data in enumerate(val_loader_train):
            # pass data to cuda
            input = data[0].to(device)
            label = data[1].to(device) 

            # compute output
            output, feature = model(input)

            loss = criterion(output, label)

            #predict --> convert output probabilities to predicted class
            pred = output.argmax(1)

            # measure accuracy and record loss
            prec1, _ = accuracy(output, label, topk=(1, 5))
            losses.update(loss.item())
            top1.update(prec1.item(), input.size(0))
         
            
            # Projection LR
            feat_np = feature.data.cpu().numpy()
            output_np = output.data.cpu().numpy()
            target_np = label.data.cpu().numpy()
            data_np = input.data.cpu().numpy()

            feat_.append(feat_np)
            out_output.append(output_np)
            out_target.append(target_np[:, np.newaxis])
            out_data.append(np.squeeze(data_np))

            feat_array = np.concatenate(feat_, axis=0)
            output_array = np.concatenate(out_output, axis=0)
            target_array = np.concatenate(out_target, axis=0)
            data_array = np.concatenate(out_data, axis=0)

        np.save('feat_layer1.npy',feat_array, allow_pickle=False)
        np.save('output1.npy', output_array, allow_pickle=False)
        np.save('target1.npy', target_array, allow_pickle=False)
        np.save('data1.npy', data_array, allow_pickle=False)

          
            
            # plot progress
        if batch_idx == len(train_loader) :
          print('({batch}/{size}) |  Loss: {loss:.4f} | top1: {top1: .4f} '.format(
                      batch=batch_idx + 1,
                      size=len(train_loader),
                      loss=losses.avg,
                      top1=top1.avg,
                      ))

    return (losses.avg, top1.avg)
